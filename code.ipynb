{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sales forecasting of Corporation Favorita Stores using Time Series Regression.**\n",
    "\n",
    "## **Objective:** \n",
    "### To develop a predictive model for store sales for Corporation Favorita, a large grocery retailer headquartered in Ecuador. The model aims to predict the unit sales of numerous items across various Favorita stores, enabling more precise estimation of sales performance.\n",
    "\n",
    "## Hypotheses for testing:\n",
    "Hypothesis 1: <br>\n",
    "```Null```: The promotional activities, oil prices, and holidays/events do not have a significant impact on store sales for Corporation Favorita.<br>\n",
    "```Alternate```: The promotional activities, oil prices, and holidays/events have a significant impact on store sales for Corporation Favorita.\n",
    "\n",
    "Hypothesis 2: <br>\n",
    "```Null```: Sales increase over time. <br>\n",
    "```Alternate```: Sales dont increase with time.\n",
    "\n",
    "Hypothesis 3: <br>\n",
    "```Null```: Situating a startup in a particular city does not influence funding.<br>\n",
    "```Alternate```: Situating a startup in a particular city significantly affects funding.\n",
    "\n",
    "### Hypothesis 4: <br>\n",
    "```Null```: The more the transactions the higher the sales. <br>\n",
    "```Alternate```: Transactions don't have an impact on sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "# Statistical Analysis\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from matplotlib.dates import MonthLocator\n",
    "\n",
    "\n",
    "# Other Packages\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Acquistion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "database = environment_variables.get(\"database\")\n",
    "server = environment_variables.get(\"server\")\n",
    "username = environment_variables.get(\"user\")\n",
    "password = environment_variables.get(\"password\")\n",
    "\n",
    "\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library and pass in the connection string.\n",
    "# This will connect to the server and might take a few seconds to be complete. \n",
    "# Check your internet connection if it takes more time than necessary\n",
    "\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SQL queries for each table\n",
    "query1 = 'SELECT * FROM dbo.oil'\n",
    "query2 = 'SELECT * FROM dbo.holidays_events'\n",
    "query3 = 'SELECT * FROM dbo.stores'\n",
    "\n",
    "# Read data from tables into pandas DataFrames\n",
    "oil = pd.read_sql(query1, connection)\n",
    "holidays_events = pd.read_sql(query2, connection)\n",
    "stores = pd.read_sql(query3, connection)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\" style =\"background-color : #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px;\n",
    "              color:black;\">ðŸ“Œ Renaming the type in holiday data to holiday type\n",
    "    </h4>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "holidays_events.head()\n",
    "\n",
    "\n",
    "# Rename the 'type' column to 'holiday_type'\n",
    "holidays_events.rename(columns={\n",
    "    'type': 'holiday_type'\n",
    "}, inplace=True)\n",
    "\n",
    "# Print the modified DataFrame to see the changes\n",
    "holidays_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename type here as holiday type and concat with oil['dailyoilprices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.head()  # View the first 5 rows of the stores dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission.head() ''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do away with this set since sales has no values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('data/transactions.csv')   # load the transactions data\n",
    "transactions.head()   # View the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')   # load the train data\n",
    "train.sample(5)    # View the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train['sales'] == 770) & (train['store_nbr'] == 25) ]  # Check for rows in train data whose sales is 770 and store number is 25\n",
    "                                                              # This is to confirm if sales is same as transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oil.to_csv('data/oil.csv',index=False)\n",
    "# transactions.to_csv('data/transactions.csv',index=False)\n",
    "# holidays_events.to_csv('data/holidays_events.csv',index=False)\n",
    "# stores.to_csv('data/stores.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join to display data contained in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the 'transactions.csv' file and create a DataFrame named 'transactions'\n",
    "transactions = pd.read_csv('data/transactions.csv')\n",
    "\n",
    "# Merge the 'transactions' DataFrame with the 'train' DataFrame\n",
    "# This combines the data from both DataFrames based on their common columns, creating a new DataFrame named 'full_transaction'\n",
    "full_transaction = pd.merge(transactions, train)\n",
    "\n",
    "# Display a random sample of 5 rows from the 'full_transaction' DataFrame\n",
    "# The 'sample()' function is used to extract a random subset of rows from the DataFrame for inspectionctions\n",
    "full_transaction.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the full transactions based on stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the 'full_transaction' DataFrame with the 'stores' DataFrame\n",
    "# This combines the data based on the 'store_nbr' column, using an 'inner' join type\n",
    "# The result is a new DataFrame named 'result'\n",
    "\n",
    "result = pd.merge(full_transaction, stores, on='store_nbr', how='inner')\n",
    "result.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the full transactions based on oil data for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'result' DataFrame with the 'oil' DataFrame\n",
    "# This combines the data based on the 'date' column, using an 'inner' join type\n",
    "# The result is a new DataFrame named 'result1'\n",
    "result1= pd.merge(result, oil, on='date', how='inner')\n",
    "result1.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the full transactions based on holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'result1' DataFrame with the 'holidays_events' DataFrame\n",
    "# This combines the data based on the 'date' column, using an 'inner' join type\n",
    "# The result is a new DataFrame named 'salesdata'\n",
    "\n",
    "salesdata= pd.merge(result1, holidays_events, on='date', how='inner')\n",
    "\n",
    "# Reset the index of the 'salesdata' DataFrame\n",
    "# The 'drop=True' parameter removes the current index, and 'inplace=True' applies the change directly to the DataFrame\n",
    "salesdata.reset_index(drop=True,inplace=True)\n",
    "salesdata.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop some columns (id column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salesdata.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename store_nbr as store_number amd dcpo;wtocp as oil_prices\n",
    "\n",
    "salesdata.rename(columns={\n",
    "    'store_nbr': 'store_number',\n",
    "    'dcoilwtico': 'oil_prices',\n",
    "}, inplace=True)\n",
    "salesdata.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata.columns  # Get the column names of the salesdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata = salesdata[['id','date',  'store_number', 'transactions', 'family', 'sales',\n",
    "       'onpromotion', 'city', 'state', 'type', 'cluster', 'oil_prices',\n",
    "       'holiday_type', 'locale', 'locale_name', 'description', 'transferred']] # Rearrange columns of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata.head()   # Get first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generate summary statistics and transpose the rows and columns of the resultant DataFrame then trnsposing for a detailed view.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics for the 'salesdata' DataFrame\n",
    "# The 'describe()' function computes various summary statistics for numerical columns\n",
    "# The 'T' attribute is used to transpose the summary statistics for better readability\n",
    "salesdata.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Checking for duplicate rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows in the 'salesdata' DataFrame\n",
    "# The 'duplicated()' function returns a boolean Series indicating whether each row is a duplicate\n",
    "# The 'sum()' function then counts the number of 'True' (duplicated) values in the Series\n",
    "salesdata.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\" style =\"background-color : #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px;\n",
    "              color:black;\">ðŸ“Œ There are no duplicate rows!\n",
    "    </h4>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata.to_csv('data/FavoritaStores_Data.csv', index=False)  # Save new data frame as FavoritaStores_Data which is a csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\" style =\"background-color : #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px;\n",
    "              color:black;\">ðŸ“Œ Data saved to a csv file for further analysis in BI\n",
    "    </h4>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Univariate Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Both histograms and boxplot are plotted to show distributions and any presence of outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **2.1. Sales column**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the histogram on the first subplot (ax1)\n",
    "ax1.hist(salesdata['sales'], bins=20)\n",
    "ax1.set_xlabel('Sales')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Sales')\n",
    "\n",
    "# Plot the boxplot on the second subplot (ax2)\n",
    "ax2.boxplot(salesdata['sales'])\n",
    "ax2.set_ylabel('Sales')\n",
    "ax2.set_title('Boxplot of Sales')\n",
    "\n",
    "# Adjust layout to avoid overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "    From our plots:<br><br>\n",
    "        ðŸ“Œ Sales is positively skewed. <br> <br>\n",
    "        ðŸ“Œ The median value is thus closer to the first quartile. <br><br>\n",
    "        ðŸ“Œ The boxplot shows presence of very extreme values. <br><br>        \n",
    "        ðŸ“Œ There is a high range between the values.\n",
    "    </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **2.2. Transactions column**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the histogram on the first subplot (ax1)\n",
    "ax1.hist(salesdata['transactions'], bins=20)\n",
    "ax1.set_xlabel('transactions')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of transactions')\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "# Plot the boxplot on the second subplot (ax2)\n",
    "ax2.boxplot(salesdata['transactions'])\n",
    "ax2.set_ylabel('transactions')\n",
    "ax2.set_title('Boxplot of transactions')\n",
    "\n",
    "# Adjust layout to avoid overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "    From the plots:<br>\n",
    "        ðŸ“Œ The transactions are positively skewed.<br><br>\n",
    "        ðŸ“Œ Transactions that fall within the interval of 500 - 1500 had the most occurance.<br><br>\n",
    "        ðŸ“Œ This depicts pressence of outliers ash confirmed by the boxplot.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **2.3. Oil Prices column column**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the histogram on the first subplot (ax1)\n",
    "ax1.hist(salesdata['oil_prices'], bins=20)\n",
    "ax1.set_xlabel('oil_prices')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of oil_prices')\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "# Plot the boxplot on the second subplot (ax2)\n",
    "ax2.boxplot(salesdata['oil_prices'])\n",
    "ax2.set_ylabel('oil_prices')\n",
    "ax2.set_title('Boxplot of oil_prices')\n",
    "\n",
    "# Adjust layout to avoid overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        ðŸ“Œ The histogram displays a bimodal distribution characterized by two prominent peaks. <br><br>\n",
    "        ðŸ“Œ The first peak is observed in the interval between 40 and 55, indicating a concentration of data points in this range. <br><br>\n",
    "        ðŸ“Œ This suggests that a significant portion of the dataset falls within this range, leading to a higher frequency count within this interval.<br><br>\n",
    "        ðŸ“Œ The second peak occurs in the interval between 98 and 100. <br><br>\n",
    "        ðŸ“Œ This peak signifies another concentration of data points in this range, which is distinct from the first peak. <br><br>\n",
    "        ðŸ“Œ The presence of two distinct peaks suggests the existence of two modes or clusters within the dataset.<br><br>\n",
    "        ðŸ“Œ Maybe this phenomenon is due to the pressence of some missing data.\n",
    "        \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **2.4. Onpromotion column**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the histogram on the first subplot (ax1)\n",
    "ax1.hist(salesdata['onpromotion'], bins=20)\n",
    "ax1.set_xlabel('onpromotion')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of onpromotion')\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "# Plot the boxplot on the second subplot (ax2)\n",
    "ax2.boxplot(salesdata['onpromotion'])\n",
    "ax2.set_ylabel('onpromotion')\n",
    "ax2.set_title('Boxplot of onpromotion')\n",
    "\n",
    "# Adjust layout to avoid overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "    From our plots:<br><br>\n",
    "        ðŸ“Œ onpromotion is positively skewed. <br> <br>\n",
    "        ðŸ“Œ The median value is thus closer to the first quartile. <br><br>\n",
    "        ðŸ“Œ The boxplot shows presence of very extreme values. <br><br>        \n",
    "        ðŸ“Œ There is a high range between the values.\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Bivariate Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **3.1. Trend of Daily average sales**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column in the data to python date format\n",
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "# Group by data and obtain mean sales\n",
    "salesdata_daily=salesdata.groupby('date')['sales'].mean()\n",
    "# Define the size of plot area\n",
    "plt.figure(figsize= (12,6))\n",
    "# Plot the dates by mean sales\n",
    "plt.plot(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Daily average Sales over Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the 'date' column in the 'salesdata' DataFrame to datetime format\n",
    "salesdata['date'] = pd.to_datetime(salesdata['date'])\n",
    "\n",
    "# Extract the year from the 'date' column and create a new 'year' column\n",
    "salesdata['year'] = salesdata['date'].dt.year\n",
    "\n",
    "# Group the sales data by 'year', summing up the 'sales' column for each year\n",
    "salesdata_yearly = salesdata.groupby('year')['sales'].sum()\n",
    "\n",
    "# Create a new figure for the plot with a specified size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot using years as x-axis and their corresponding total sales as y-axis\n",
    "plt.plot(salesdata_yearly.index, salesdata_yearly.values, marker='o')\n",
    "\n",
    "# Set the label for the x-axis\n",
    "plt.xlabel('Year')\n",
    "\n",
    "# Set the label for the y-axis\n",
    "plt.ylabel('Total Sales')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Total Sales by Year')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'date' column to datetime format\n",
    "salesdata['date'] = pd.to_datetime(salesdata['date'])\n",
    "\n",
    "# Grouping the sales data by date and calculating the mean sales for each day\n",
    "salesdata_daily = salesdata.groupby('date')['sales'].mean()\n",
    "salesdata_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "    From our plot:<br><br>\n",
    "        ðŸ“Œ Daily average sales exhibit an upward trend over the years, except from 2017. <br> <br>\n",
    "        ðŸ“Œ There are some seasonal peaks in each year as well, especially at the end of each year. <br><br>        \n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **3.2. Trend of Daily Average Oil Prices**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'date' column to datetime format\n",
    "salesdata['date'] = pd.to_datetime(salesdata['date'])\n",
    "\n",
    "# Grouping the data by year and calculating the mean oil prices for each year\n",
    "salesdata_yearly = salesdata.groupby(salesdata['date'].dt.year)['oil_prices'].mean()\n",
    "\n",
    "# Creating a new figure for the plot with a specified size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Creating a line plot of mean oil prices by year\n",
    "plt.plot(salesdata_yearly.index, salesdata_yearly.values)\n",
    "\n",
    "# Adding a label to the x-axis\n",
    "plt.xlabel('Year')\n",
    "\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Mean Oil Prices')\n",
    "\n",
    "# Adding a title to the plot\n",
    "plt.title('Mean Oil Prices by Year')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata_yearly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'date' column to datetime format\n",
    "salesdata['date'] = pd.to_datetime(salesdata['date'])\n",
    "\n",
    "# Grouping the data by year and calculating the mean oil prices for each year\n",
    "salesdata_yearly = salesdata.groupby(salesdata['date'].dt.year)['oil_prices'].mean()\n",
    "\n",
    "# Creating a new figure for the plot with a specified size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Creating a bar plot of mean oil prices by year\n",
    "plt.bar(salesdata_yearly.index, salesdata_yearly.values)\n",
    "\n",
    "# Adding a label to the x-axis\n",
    "plt.xlabel('Year')\n",
    "\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Mean Oil Prices')\n",
    "\n",
    "# Adding a title to the plot\n",
    "plt.title('Mean Oil Prices by Year')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **3.3. Sales against holiday type**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata.groupby('holiday_type')['sales'].sum()\n",
    "plt.figure(figsize= (12,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('Holiday Type')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Sales count against Holidays')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        ðŸ“Œ There were more sales on holidyas than any other day with the least being a bridge day\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **3.3. Sales against store number**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata.groupby('store_number')['sales'].sum().head(10)\n",
    "salesdata_daily= salesdata_daily.sort_values(ascending=False)\n",
    "plt.figure(figsize= (12,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('Store Number')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Top 10 Sales Count against Store Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata.groupby('store_number')['sales'].sum().tail(10)\n",
    "salesdata_daily= salesdata_daily.sort_values(ascending=False)\n",
    "plt.figure(figsize= (12,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('Store Number')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Bottom 10 Sales Count against Store Number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        ðŸ“Œ After displaying both the top 10 and bottom 10 most store salers the highest store seller was store number 3 and the bottom store seller being store number 52.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.4 Sales against Product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata.groupby('family')['sales'].sum().head(10)\n",
    "salesdata_daily= salesdata_daily.sort_values(ascending=False)\n",
    "plt.figure(figsize= (15,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('Product Sold')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Top 10 Sales Count against Product Sold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        ðŸ“Œ After displaying the top 10 product with most sales beverages were the leading products followed by cleaning products\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.5 Sales against State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata.groupby('state')['sales'].sum().head(10)\n",
    "salesdata_daily= salesdata_daily.sort_values(ascending=False)\n",
    "plt.figure(figsize= (15,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Top 10 Sales Count against State')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata[salesdata['state']=='Guayas']\n",
    "salesdata_daily=salesdata.groupby('city')['sales'].sum().head(10)\n",
    "salesdata_daily= salesdata_daily.sort_values(ascending=False)\n",
    "plt.figure(figsize= (15,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('Various cities in Guayas')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Sales Count in Various series in Guayas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        ðŸ“Œ Most sales where recorded in the state of Guayas. Given the state of Guayas the highest city with most sales in Guayas is Guayaquil\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.6. Sales against type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "salesdata_daily=salesdata.groupby('type')['sales'].sum().head(10)\n",
    "salesdata_daily= salesdata_daily.sort_values(ascending=False)\n",
    "plt.figure(figsize= (15,6))\n",
    "plt.bar(salesdata_daily.index,salesdata_daily.values)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Sales Count')\n",
    "plt.title('Top 10 Sales Count against State')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        ðŸ“Œ Most sales where related to product of type D and the least of product type E\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Time Series Analysis of sales by resampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We visualize the time series of sales across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose date and sales columns\n",
    "timeseriesdata=salesdata[['sales','date']]\n",
    "timeseriesdata.index = timeseriesdata['date']\n",
    "timeseriesdata\n",
    "# make date the index\n",
    "del timeseriesdata['date']\n",
    "timeseriesdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **4.1. Yearly Series of Total Sales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_year= timeseriesdata.resample('Y').sum()\n",
    "plt.figure(figsize= (15,6))\n",
    "sns.lineplot(sales_per_year)\n",
    "plt.ylabel('Sales')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **4.2. Analyzing monthly sales across each year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseriesdata= timeseriesdata.resample('M').sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **4.2.1. Year 2013**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2013 = timeseriesdata[timeseriesdata.index.year == 2013]\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Create the line plot using Seaborn\n",
    "sns.lineplot(data=data2013)\n",
    "# Set x-axis locator to one-month interval\n",
    "plt.gca().xaxis.set_major_locator(MonthLocator(interval=1))\n",
    "plt.ylabel('2013 Sales')\n",
    "plt.title('Sales Data for the Year 2013')\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **4.2.2. Year 2014**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014 = timeseriesdata[timeseriesdata.index.year == 2014]\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Create the line plot using Seaborn\n",
    "sns.lineplot(data=data2014)\n",
    "# Set x-axis locator to one-month interval\n",
    "plt.gca().xaxis.set_major_locator(MonthLocator(interval=1))\n",
    "plt.ylabel('2014 Sales')\n",
    "plt.title('Sales Data for the Year 2014')\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **4.2.3. Year 2015**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015 = timeseriesdata[timeseriesdata.index.year == 2015]\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Create the line plot using Seaborn\n",
    "sns.lineplot(data=data2015)\n",
    "# Set x-axis locator to one-month interval\n",
    "plt.gca().xaxis.set_major_locator(MonthLocator(interval=1))\n",
    "plt.ylabel('2015 Sales')\n",
    "plt.title('Sales Data for the Year 2015')\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **4.2.4. Year 2016**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 = timeseriesdata[timeseriesdata.index.year == 2016]\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Create the line plot using Seaborn\n",
    "sns.lineplot(data=data2016)\n",
    "# Set x-axis locator to one-month interval\n",
    "plt.gca().xaxis.set_major_locator(MonthLocator(interval=1))\n",
    "plt.ylabel('2016 Sales')\n",
    "plt.title('Sales Data for the Year 2016')\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **4.2.5. Year 2013**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017 = timeseriesdata[timeseriesdata.index.year == 2017]\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Create the line plot using Seaborn\n",
    "sns.lineplot(data=data2017)\n",
    "# Set x-axis locator to one-month interval\n",
    "plt.gca().xaxis.set_major_locator(MonthLocator(interval=1))\n",
    "plt.ylabel('2017 Sales')\n",
    "plt.title('Sales Data for the Year 2017')\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3. Sales series across months**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by month and calculate the sum of sales\n",
    "monthly_sales = salesdata.groupby(salesdata['date'].dt.strftime('%B'))['sales'].sum()\n",
    "# List of month names in order\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "# Convert month names to categorical with specified order\n",
    "monthly_sales.index = pd.Categorical(monthly_sales.index, categories=month_order, ordered=True)\n",
    "# Sort the index to order the months\n",
    "monthly_sales = monthly_sales.sort_index()\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Create the line plot using Seaborn\n",
    "plt.plot(monthly_sales)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        The sales start increasing from september but exponentionally increase from October to December and from March to April. The highest purchases where witnessed in December and the lowest in September.\n",
    "    </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.4. Sales Series in Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdata['date']=pd.to_datetime(salesdata['date'])\n",
    "daily_sales = salesdata.groupby(salesdata['date'].dt.day)['sales'].sum().reset_index()\n",
    "\n",
    "# Create a time series plot with slider\n",
    "fig = px.line(daily_sales, x='date', y='sales')\n",
    "fig.update_xaxes(rangeslider_visible=True)\n",
    "fig.update_layout(title='Trend of Sales Over Time', title_x=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        The highest sales are recorded at the beginning and at the end of the month.\n",
    "    </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sales Series Quarterly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_quarter=timeseriesdata.resample('Q').sum()\n",
    "plt.figure(figsize= (15,6))\n",
    "sns.lineplot(sales_per_quarter)\n",
    "plt.ylabel('Sales')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **MultiVariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical variables for correlation analysis\n",
    "numerical_vars = ['sales', 'transactions', 'oil_prices','onpromotion']\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = salesdata[numerical_vars].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        There is a significant relationship between number of items on promotion with slaes as well as a week relation with transactions and sales.\n",
    "    </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Testing Hypothesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before hypothesis testing we explore the distribution of sales.Using shapiro wilk test to explore distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Year Funded'\n",
    "grouped_data = salesdata.groupby('date')['sales'].sum()\n",
    "grouped_data\n",
    "# Perform Shapiro-Wilk test for each group\n",
    "statistic, p_value = stats.shapiro(grouped_data)\n",
    "print(\"Shapiro-Wilk Test Results:\")\n",
    "print(\"Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"The data does not follow a normal distribution.\")\n",
    "else:\n",
    "    print(\"The data follows a normal distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        The sales do not follow normal distribution.\n",
    "    </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The distribution is not normal hence non parametric ANOVA is used.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Hypothesis 1: <br>**\n",
    "#### ```Null```: The promotional activities, oil prices, and holidays/events do not have a significant impact on store sales for Corporation Favorita.<br>\n",
    "#### ```Alternate```: The promotional activities, oil prices, and holidays/events have a significant impact on store sales for Corporation Favorita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### On promotion .In this we use a scatterplot analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"background-color: #e6ebef;\">\n",
    "    <h4 style=\"padding: 15px; color: black;\">\n",
    "        The sales do not follow normal distribution.\n",
    "    </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hypothesis 2: <br>**\n",
    "### ```Null```: Sales increase over time. <br>\n",
    "### ```Alternate```: Sales dont increase with time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hypothesis 3: <br>**\n",
    "### ```Null```: Situating a startup in a particular city does not influence funding.<br>\n",
    "### ```Alternate```: Situating a startup in a particular city significantly affects funding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hypothesis 4: <br>**\n",
    "### ```Null```: The more the transactions the higher the sales. <br>\n",
    "### ```Alternate```: Transactions don't have an impact on sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
